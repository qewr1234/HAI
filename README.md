
# ğŸš— Car Classification

**HAI(í•˜ì´)! - Hecto AI Challenge 2025** ì¤‘ê³ ì°¨ ì´ë¯¸ì§€ ì°¨ì¢… ë¶„ë¥˜ ëŒ€íšŒ

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ† Result

| Metric | Score |
|--------|-------|
| **Final Rank** | **90th / 748 teams (Top 12%)** |

---

## ğŸ“‹ Competition Overview

### ë°°ê²½
ìµœê·¼ ìë™ì°¨ ì‚°ì—…ì˜ ë””ì§€í„¸ ì „í™˜ê³¼ ë”ë¶ˆì–´, ë‹¤ì–‘í•œ ì°¨ì¢…ì„ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì¸ì‹í•˜ëŠ” ê¸°ìˆ ì˜ ì¤‘ìš”ì„±ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì¤‘ê³ ì°¨ ê±°ë˜ í”Œë«í¼, ì°¨ëŸ‰ ê´€ë¦¬ ì‹œìŠ¤í…œ, ìë™ ì£¼ì°¨ ë° ë³´ì•ˆ ì‹œìŠ¤í…œ ë“± ì‹¤ìƒí™œì— ë°€ì ‘í•œ ë¶„ì•¼ì—ì„œ ì •í™•í•œ ì°¨ì¢… ë¶„ë¥˜ê°€ í•µì‹¬ ê¸°ìˆ ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.

### ì£¼ì œ
**ì¤‘ê³ ì°¨ ì´ë¯¸ì§€ ì°¨ì¢… ë¶„ë¥˜ AI ëª¨ë¸ ê°œë°œ**

ë‹¤ì–‘í•œ ì¤‘ê³ ì°¨ ì°¨ì¢… ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 396ê°œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” AI ëª¨ë¸ ê°œë°œ

### ì£¼ìµœ / ì£¼ê´€
- **ì£¼ìµœ**: í—¥í† (Hecto)
- **ì£¼ê´€**: ë°ì´ì½˜(Dacon)

### í‰ê°€ ì§€í‘œ
**Log Loss (Cross Entropy)**

$$\text{LogLoss} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} y_{ij} \log(p_{ij})$$

- N: ì „ì²´ ìƒ˜í”Œ ìˆ˜
- C: í´ë˜ìŠ¤ ìˆ˜ (396ê°œ)
- $y_{ij}$: ië²ˆì§¸ ìƒ˜í”Œì˜ ì •ë‹µ í´ë˜ìŠ¤ê°€ jì´ë©´ 1, ì•„ë‹ˆë©´ 0
- $p_{ij}$: ië²ˆì§¸ ìƒ˜í”Œì— ëŒ€í•´ ëª¨ë¸ì´ í´ë˜ìŠ¤ jë¼ê³  ì˜ˆì¸¡í•œ í™•ë¥ 

### ë°ì´í„°ì…‹

| êµ¬ë¶„ | ì„¤ëª… |
|------|------|
| Train | 396ê°œ í´ë˜ìŠ¤, ì´ 33,137ì¥ |
| Test | 8,258ì¥ |
| Classes | 396ê°œ ì°¨ì¢… |

**ë™ì¼ í´ë˜ìŠ¤ ì²˜ë¦¬:**
- K5_3ì„¸ëŒ€_í•˜ì´ë¸Œë¦¬ë“œ_2020_2022 = K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2020_2023
- ë””_ì˜¬ë‰´ë‹ˆë¡œ_2022_2025 = ë””_ì˜¬_ë‰´_ë‹ˆë¡œ_2022_2025
- 718_ë°•ìŠ¤í„°_2017_2024 = ë°•ìŠ¤í„°_718_2017_2024
- RAV4_2016_2018 = ë¼ë¸Œ4_4ì„¸ëŒ€_2013_2018
- RAV4_5ì„¸ëŒ€_2019_2024 = ë¼ë¸Œ4_5ì„¸ëŒ€_2019_2024

---

## ğŸ›  Solution

### Model
- **Backbone**: ConvNeXt-Base (ImageNet-22k pretrained)
- **Input Size**: 384 Ã— 384

### Training Techniques
| Technique | Description |
|-----------|-------------|
| **AMP** | Mixed Precision Training (FP16) |
| **EMA** | Exponential Moving Average (decay=0.9998) |
| **SWA** | Stochastic Weight Averaging |
| **CutMix** | ì´ë¯¸ì§€ ì¼ë¶€ë¥¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´ |
| **MixUp** | ë‘ ì´ë¯¸ì§€ë¥¼ ì„ í˜• ë³´ê°„ìœ¼ë¡œ í˜¼í•© |
| **R-Drop** | ë™ì¼ ì…ë ¥ì— 2ë²ˆ forward â†’ KL divergence ìµœì†Œí™” |
| **Label Smoothing** | 0.1 smoothing factor |

### Inference
- **TTA**: Test-Time Augmentation (5 transforms)
- **Ensemble**: Top-3 checkpoint averaging

---

## ğŸ“ Project Structure

```
car_classification/
â”œâ”€â”€ config.py        # Configuration dataclass
â”œâ”€â”€ dataset.py       # Dataset & augmentation (CutMix, MixUp)
â”œâ”€â”€ model.py         # Model, EMA, SWA, Loss functions
â”œâ”€â”€ trainer.py       # Training logic
â”œâ”€â”€ inference.py     # Inference & TTA
â”œâ”€â”€ utils.py         # Utility functions
â”œâ”€â”€ train.py         # Main training script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Data Download

ë°ì´í„°ì…‹ì€ ëŒ€íšŒ í˜ì´ì§€ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤:
- [ë°ì´ì½˜ ëŒ€íšŒ í˜ì´ì§€](https://dacon.io/competitions/official/236493/overview/description)

ë‹¤ìš´ë¡œë“œ í›„ ì•„ë˜ êµ¬ì¡°ë¡œ ë°°ì¹˜:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ ê·¸ëœì €_6ì„¸ëŒ€_í•˜ì´ë¸Œë¦¬ë“œ_2016_2019/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ì†Œë‚˜íƒ€_DN8_2019_2023/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ... (396 classes)
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ TEST_00000.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test.csv
â””â”€â”€ sample_submission.csv
```

### Training

```bash
# Basic training
python train.py --config base

# Light (faster, lower VRAM)
python train.py --config light

# Heavy (better performance)
python train.py --config heavy

# Custom
python train.py \
    --train_dir ./data/train \
    --test_dir ./data/test \
    --epochs 30 \
    --batch_size 32
```

### Inference Only

```bash
python train.py --eval_only --output_dir ./outputs
```

---

## âš™ï¸ Configuration

### Presets

| Preset | Model | Image Size | Batch | Epochs | VRAM |
|--------|-------|------------|-------|--------|------|
| `light` | ConvNeXt-Small | 224 | 64 | 20 | ~8GB |
| `base` | ConvNeXt-Base | 384 | 32 | 30 | ~16GB |
| `heavy` | ConvNeXt-Large | 384 | 16 | 40 | ~24GB |

### Command Line Options

```bash
--model_name convnext_base.fb_in22k_ft_in1k
--img_size 384
--batch_size 32
--epochs 30
--lr 1e-4
--no_amp      # Disable mixed precision
--no_ema      # Disable EMA
--no_rdrop    # Disable R-Drop
```

---

## ğŸ“š References

- [ConvNeXt: A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
- [R-Drop: Regularized Dropout for Neural Networks](https://arxiv.org/abs/2106.14448)
- [CutMix: Regularization Strategy to Train Strong Classifiers](https://arxiv.org/abs/1905.04899)
- [MixUp: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)

---

## ğŸ“ License

MIT License
